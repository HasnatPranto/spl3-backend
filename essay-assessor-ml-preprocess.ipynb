{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca7ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918839a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./training_set_rel3.tsv\", sep='\\t', encoding='ISO-8859-1')\n",
    "df = df.dropna(axis=1)\n",
    "df = df.drop(columns=['rater1_domain1', 'rater2_domain1'])\n",
    "#max(df[df['essay_set']==8]['domain1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd7f120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score  final_score  \n",
       "0              8            6  \n",
       "1              9            7  \n",
       "2              7            5  \n",
       "3             10            8  \n",
       "4              8            6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_range = [2,1,0,0,0,0,0,0]\n",
    "max_range = [12,6,3,3,4,4,30,60]\n",
    "\n",
    "def normalize(x,minScore,maxScore):\n",
    "     x = (x-minScore)/(maxScore-minScore)\n",
    "     return round(x*10)\n",
    "\n",
    "df['final_score']=df.apply(lambda x:normalize(x['domain1_score'],min_range[x['essay_set']-1],max_range[x['essay_set']-1]),axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c631676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_essay(essay):\n",
    "    x=[]\n",
    "    for i in essay.split():\n",
    "        if i.startswith(\"@\"):\n",
    "            continue\n",
    "        else:\n",
    "            x.append(i)\n",
    "    return ' '.join(x)\n",
    "\n",
    "df['essay'] = df['essay'].apply(lambda x:clean_essay(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a789283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "def remove_stop_words(essay):\n",
    "    word_tokens = word_tokenize(essay) \n",
    "    filtered_sentence = [] \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "df['clean_essay'] = df['essay'].apply(lambda x:remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15f01e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>final_score</th>\n",
       "      <th>clean_essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>Dear local newspaper  I think effects computer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear I believe that using computers will benef...</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>Dear I believe using computers benefit us many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, More and more people use computers, but ...</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>Dear  More people use computers  everyone agre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, I have found that many e...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear Local Newspaper  I found many experts say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear I know having computers has a positive ef...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>Dear I know computers positive effect people  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear I believe that using computers will benef...   \n",
       "2         3          1  Dear, More and more people use computers, but ...   \n",
       "3         4          1  Dear Local Newspaper, I have found that many e...   \n",
       "4         5          1  Dear I know having computers has a positive ef...   \n",
       "\n",
       "   domain1_score  final_score  \\\n",
       "0              8            6   \n",
       "1              9            7   \n",
       "2              7            5   \n",
       "3             10            8   \n",
       "4              8            6   \n",
       "\n",
       "                                         clean_essay  \n",
       "0  Dear local newspaper  I think effects computer...  \n",
       "1  Dear I believe using computers benefit us many...  \n",
       "2  Dear  More people use computers  everyone agre...  \n",
       "3  Dear Local Newspaper  I found many experts say...  \n",
       "4  Dear I know computers positive effect people  ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_puncs(essay):\n",
    "    essay = re.sub(\"[^A-Za-z ]\",\"\",essay)\n",
    "    return essay\n",
    "\n",
    "df['clean_essay'] = df['clean_essay'].apply(lambda x:remove_puncs(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b75adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2word(x):\n",
    "    x=re.sub(\"[^A-Za-z0-9]\",\" \",x)\n",
    "    words=nltk.word_tokenize(x)\n",
    "    return words\n",
    "\n",
    "def essay2word(essay):\n",
    "    essay = essay.strip()\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw = tokenizer.tokenize(essay)\n",
    "    final_words=[]\n",
    "    for i in raw[:1]:\n",
    "        if(len(i)>0):\n",
    "            final_words.append(sent2word(i))\n",
    "    return final_words\n",
    "        \n",
    "\n",
    "def noOfWords(essay):\n",
    "    count=0\n",
    "    for i in essay2word(essay):\n",
    "        count=count+len(i)\n",
    "    return count\n",
    "\n",
    "def noOfChar(essay):\n",
    "    count=0\n",
    "    for i in essay2word(essay):\n",
    "        for j in i:\n",
    "            count=count+len(j)\n",
    "    return count\n",
    "\n",
    "def avg_word_len(essay):\n",
    "    words = noOfWords(essay)\n",
    "    if words == 0:\n",
    "        return 0\n",
    "    return noOfChar(essay)/words\n",
    "\n",
    "def noOfSent(essay):\n",
    "    return len(essay2word(essay))\n",
    "\n",
    "def count_pos(essay):\n",
    "    sentences = essay2word(essay)\n",
    "    noun_count=0\n",
    "    adj_count=0\n",
    "    verb_count=0\n",
    "    adverb_count=0\n",
    "    for i in sentences:\n",
    "        pos_sentence = nltk.pos_tag(i)\n",
    "        for j in pos_sentence:\n",
    "            pos_tag = j[1]\n",
    "            if(pos_tag[0]=='N'):\n",
    "                noun_count+=1\n",
    "            elif(pos_tag[0]=='V'):\n",
    "                verb_count+=1\n",
    "            elif(pos_tag[0]=='J'):\n",
    "                adj_count+=1\n",
    "            elif(pos_tag[0]=='R'):\n",
    "                adverb_count+=1\n",
    "    \n",
    "    return noun_count,verb_count,adj_count,adverb_count\n",
    "\n",
    "\n",
    "def check_spell_error(essay):\n",
    "    essay=essay.lower()\n",
    "    new_essay = re.sub(\"[^A-Za-z0-9]\",\" \",essay)\n",
    "    new_essay = re.sub(\"[0-9]\",\"\",new_essay)\n",
    "    count=0\n",
    "    all_words = new_essay.split()\n",
    "    for i in all_words:\n",
    "        if i not in words:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "data = open('big.txt').read()\n",
    "words = re.findall('[a-z]+', data.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0601b67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features = 10000, ngram_range=(1, 3), stop_words='english')\n",
    "#count_vectors = vectorizer.fit_transform(df['clean_essay'])\n",
    "\n",
    "cv = vectorizer.fit(df['clean_essay'])\n",
    "count_vectors = vectorizer.transform(df['clean_essay'])\n",
    "pickle.dump(cv, open(\"vector.pickle\", \"wb\"))\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "data = df[['essay_set','clean_essay','final_score']].copy()\n",
    "X = count_vectors.toarray()\n",
    "y = data['final_score'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ec2d9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 2.14\n"
     ]
    }
   ],
   "source": [
    "#rf = RandomForestRegressor(n_estimators = 2, random_state = 42)\n",
    "#rf.fit(X_train, y_train)\n",
    "#pickle.dump(rf, open('RF_without_PP.sav', 'wb'))\n",
    "\n",
    "#Use Saved Model\n",
    "rf = pickle.load(open('RF_without_PP', 'rb'))\n",
    "predictions = rf.predict(X_test)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac03d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pro_data = df.copy()\n",
    "# pro_data['char_count'] = pro_data['essay'].apply(noOfChar)\n",
    "# pro_data['word_count'] = pro_data['essay'].apply(noOfWords)\n",
    "# pro_data['sent_count'] = pro_data['essay'].apply(noOfSent)\n",
    "# pro_data['avg_word_len'] = pro_data['essay'].apply(avg_word_len)\n",
    "# pro_data['spell_err_count'] = pro_data['essay'].apply(check_spell_error)\n",
    "# pro_data['noun_count'], pro_data['verb_count'], pro_data['adj_count'], pro_data['adv_count'] = zip(*pro_data['essay'].map(count_pos))\n",
    "# #pro_data['noun_count'] = pro_data['essay'].apply(count_pos)\n",
    "\n",
    "# pro_data.to_csv(\"Processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d6e3808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[183.  39.   1. ...   0.   0.   0.]\n",
      " [128.  25.   1. ...   0.   0.   0.]\n",
      " [ 76.  15.   1. ...   0.   0.   0.]\n",
      " ...\n",
      " [ 33.  10.   1. ...   0.   0.   0.]\n",
      " [ 89.  20.   1. ...   0.   0.   0.]\n",
      " [ 47.   9.   1. ...   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "prep_df = pd.read_csv(\"Processed_data.csv\")\n",
    "prep_df.drop('Unnamed: 0',inplace=True,axis=1)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features = 10000, ngram_range=(1, 3), stop_words='english')\n",
    "#count_vectors = vectorizer.fit_transform(prep_df['clean_essay'])\n",
    "\n",
    "cv = vectorizer.fit(df['clean_essay'])\n",
    "count_vectors = vectorizer.transform(df['clean_essay'])\n",
    "pickle.dump(cv, open(\"vector_additional.pickle\", \"wb\"))\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "X = count_vectors.toarray()\n",
    "X_full = np.concatenate((prep_df.iloc[:, 6:].to_numpy(), X), axis = 1)\n",
    "\n",
    "y_full = prep_df['final_score'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab4f4217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 1.28\n"
     ]
    }
   ],
   "source": [
    "#Save Trained Model\n",
    "# rf = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "# rf.fit(X_train, y_train)\n",
    "# pickle.dump(rf, open('RF_with_PP', 'wb'))\n",
    "\n",
    "#Use Saved Model\n",
    "rf = pickle.load(open('RF_with_PP', 'rb'))\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "# for i in range(500,510):\n",
    "#      print(y_pred[i],y_full[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c05b9d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8678154765344008"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "y_test_list = y_test.tolist()\n",
    "y_pred_list = []\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "#     if str(y_pred[i]) == 'nan':\n",
    "#         y_pred[i] = 0    \n",
    "     y_pred_list.append(round(y_pred[i]))\n",
    "\n",
    "kappa = cohen_kappa_score(y_test_list, y_pred_list,weights='quadratic')\n",
    "kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba7278b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f0a8fbf1307fb74e5848714fa9b66b2a70db2fc19b4d130a0cf84b306bb7724c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
